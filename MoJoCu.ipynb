{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import gym\n",
    "from pickle import load, dump\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable, Function\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from minimax_entropy import MinimaxEntropyEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ExpertDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, Y, transform=None):\n",
    "        self.transform = transform\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'observations': self.X[idx], 'actions': self.Y[idx]}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample['observations'], sample['actions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Discretizer:\n",
    "    \n",
    "    def __init__(self, bins):\n",
    "        self._bins = bins\n",
    "        \n",
    "    def fit(self, X):\n",
    "        m = 2\n",
    "        self._edges = []\n",
    "        for j in range(m):\n",
    "            _, edges = np.histogram(X[:,j], bins=self._bins)\n",
    "            self._edges.append(edges)\n",
    "    \n",
    "    def transform(self, X):\n",
    "        n = X.shape[0]\n",
    "        m = 2\n",
    "        Xd = np.zeros((n, self._bins, self._bins))\n",
    "        for i in range(n):\n",
    "            coord = []\n",
    "            for j in range(m):\n",
    "                c = X[i][j]\n",
    "                if c <= self._edges[j][0]:\n",
    "                    coord.append(0)\n",
    "                elif c >= self._edges[j][-1]:\n",
    "                    coord.append(-1)\n",
    "                else:\n",
    "                    for k in range(self._bins):\n",
    "                        if self._edges[j][k] < c <= self._edges[j][k+1]:\n",
    "                            coord.append(k)\n",
    "                            break\n",
    "            Xd[i][coord[0], coord[1]] = 1\n",
    "        return Xd.reshape(n, self._bins ** m)\n",
    "    \n",
    "    def inverse_transform(self, X):\n",
    "        n = X.shape[0]\n",
    "        m = 2\n",
    "        Xc = np.zeros((n, m))\n",
    "        X = X.reshape(n, self._bins, self._bins)\n",
    "        \n",
    "        for i in range(n):\n",
    "            j, k = np.argwhere(X[i] == 1)[0]\n",
    "            Xc[i] = np.array([self._edges[0][j] + self._edges[0][j + 1], self._edges[1][k] + self._edges[1][k + 1]])/2\n",
    "        return Xc\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_data_loaders(filename, test_size=0.3, batch_size=64, num_workers=4, pin_memory=True, bins=0):\n",
    "    with file(filename, 'r') as f:\n",
    "        data = load(f)\n",
    "    n = len(data['actions'])\n",
    "    m = data['actions'].shape[-1]\n",
    "    actions = data['actions'].reshape(n, m)\n",
    "    \n",
    "    if bins > 0:\n",
    "        d = Discretizer(bins)\n",
    "        actions = d.fit_transform(actions)\n",
    "    else:\n",
    "        d = None\n",
    "    \n",
    "    indices = np.arange(n)\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(n*test_size)\n",
    "    train_idx, test_idx = indices[split:], indices[:split]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(test_idx)\n",
    "    \n",
    "    X, Y = data['observations'], actions\n",
    "    ds_tr = ExpertDataset(X, Y)\n",
    "    ds_t = ExpertDataset(X, Y)\n",
    "    \n",
    "    train_loader = DataLoader(ds_tr, \n",
    "                    batch_size=batch_size, sampler=train_sampler, \n",
    "                    num_workers=num_workers, pin_memory=pin_memory)\n",
    "    test_loader = DataLoader(ds_t,\n",
    "                    batch_size=len(test_idx), sampler=test_sampler, \n",
    "                    num_workers=num_workers, pin_memory=pin_memory)\n",
    "    \n",
    "    return train_loader, test_loader, data, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(model, X):\n",
    "    X = Variable(torch.from_numpy(X)).cuda()\n",
    "    Y = model(X.float())\n",
    "    return Y.cpu().data.numpy()\n",
    "\n",
    "def predictD_gen(d):\n",
    "    def predictD(model, X):\n",
    "        Yd = predict(model, X)\n",
    "        Y = np.zeros((1, Yd.shape[1]))\n",
    "        Y[0, Yd.argmax()] = 1            \n",
    "        return d.inverse_transform(Y) \n",
    "    return predictD\n",
    "\n",
    "# eval model\n",
    "def eval_model(model, f, n):\n",
    "    env = gym.make('Reacher-v1')\n",
    "    returns = []\n",
    "    max_steps = env.spec.timestep_limit\n",
    "    for i in range(n):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        totalr = 0.\n",
    "        steps = 0\n",
    "        while not done:\n",
    "            action = f(model, (obs[None,:])).reshape(1, -1)\n",
    "            obs, r, done, _ = env.step(action)\n",
    "            totalr += r\n",
    "            steps += 1\n",
    "            if steps >= max_steps:\n",
    "                break\n",
    "        returns.append(totalr)\n",
    "\n",
    "    return np.mean(returns), np.std(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metric_loss_gen(L, convert_onehot=False):\n",
    "    def metric_loss(model, X, Y):\n",
    "        output = model(X.float())\n",
    "        \n",
    "        batch_size, n_classes = output.size()\n",
    "        if convert_onehot:\n",
    "            target = Variable(torch.DoubleTensor(batch_size, n_classes)).cuda()\n",
    "            for i in range(batch_size):\n",
    "                target[i, Y.data[i]] = 1.\n",
    "            pred = output\n",
    "        else:\n",
    "            target = Y\n",
    "            pred = output\n",
    "            \n",
    "        pred = pred.double()\n",
    "        losses = [L(pred[i], target[i]).data.cpu().numpy() for i in range(batch_size)]\n",
    "        return np.mean(losses)\n",
    "        \n",
    "    return metric_loss     \n",
    "            \n",
    "def train(model, opt, L, train_loader, test_loader, n_classes, epoch, f_eval,\n",
    "          n_samples=1, convert_onehot=False, log_interval=100, n_evals=50):\n",
    "    model.train()\n",
    "    \n",
    "    evals = {'tr_loss':[], 't_loss':[], 'mean_r': [], 'ts': [], 'es': []}\n",
    "    for e in range(epoch):\n",
    "        for t, (X, Y) in enumerate(train_loader):\n",
    "            X, Y = X.cuda(), Y.cuda()\n",
    "            X, Y = Variable(X), Variable(Y)\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            batch_size = Y.size()[0]\n",
    "\n",
    "            if convert_onehot:\n",
    "                target_onehot = Variable(torch.DoubleTensor(batch_size, n_classes)).cuda()\n",
    "                target_onehot.data.zero_()\n",
    "                for i in range(batch_size):\n",
    "                    target_onehot[i, Y.data[i]] = 1.\n",
    "                target = target_onehot\n",
    "            else:\n",
    "                target = Y\n",
    "\n",
    "            mean_output = Variable(torch.DoubleTensor(batch_size, n_classes)).cuda()\n",
    "            outputs = [model(X.float()).double() for _ in range(n_samples)]\n",
    "            for i in range(batch_size):\n",
    "                for output in outputs:\n",
    "                    mean_output[i] = mean_output[i] + output[i]\n",
    "            mean_output /= n_samples\n",
    "\n",
    "            loss = Variable(torch.zeros(1)).double().cuda()\n",
    "            for i in range(batch_size):\n",
    "                loss += L(output[i], target[i])\n",
    "            loss.backward()\n",
    "\n",
    "            opt.step()\n",
    "            if t % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]'.format(e, t * len(X), len(train_loader.dataset),\n",
    "                                                                    100. * t / len(train_loader)))\n",
    "                \n",
    "                model.eval()\n",
    "                tr_loss = loss.data[0] / batch_size                    \n",
    "                mean_r, std_r = eval_model(model, f_eval, n_evals)\n",
    "                \n",
    "                print('Tr Loss: {:.6f} | MeanR: {:.2f} | VarR: {:.2f}'.format(tr_loss, mean_r, std_r))\n",
    "                evals['tr_loss'].append(tr_loss)\n",
    "                evals['mean_r'].append(mean_r)\n",
    "                \n",
    "                evals['ts'].append(t)\n",
    "                evals['es'].append(e)\n",
    "                model.train()\n",
    "            \n",
    "    return evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ReacherDisModel(nn.Module):\n",
    "    def __init__(self, dropout):\n",
    "        super(ReacherDisModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(11, 100)\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.fc3 = nn.Linear(100, 225)\n",
    "        \n",
    "        self._dropout = dropout\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(F.relu(self.fc2(x)), p=self._dropout, training=self.training)\n",
    "        x = F.dropout(F.relu(self.fc3(x)), p=self._dropout, training=self.training)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "bins = 15\n",
    "\n",
    "train_loader, test_loader, reacher_data, d = get_data_loaders('expert_data/Reacher-v1.pkl',\n",
    "                                                              batch_size=batch_size, bins=bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "log_interval = 10\n",
    "dropout = 0.1\n",
    "n_samples = 50\n",
    "n_classes = bins**2\n",
    "\n",
    "entro = MinimaxEntropyEstimator('poly_coeff_entro.mat', n_samples, gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/2500 (0%)]\n",
      "Tr Loss: 0.291897 | MeanR: -18.16 | VarR: 3.70"
     ]
    }
   ],
   "source": [
    "modelD_mm = ReacherDisModel(dropout)\n",
    "modelD_mm.cuda()\n",
    "opt = optim.Adam(modelD_mm.parameters())\n",
    "\n",
    "mm_evals = train(modelD_mm, opt, entro.minimax_cross_entro_loss, train_loader, test_loader, n_classes, epochs, predictD_gen(d), \n",
    "      n_samples=n_samples, log_interval=log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/2500 (0%)]\n",
      "Tr Loss: 11.569041 | MeanR: -19.65 | VarR: 2.12\n",
      "Train Epoch: 0 [640/2500 (36%)]\n",
      "Tr Loss: 3.576886 | MeanR: -12.87 | VarR: 2.43\n",
      "Train Epoch: 0 [1280/2500 (71%)]\n",
      "Tr Loss: 1.890307 | MeanR: -11.86 | VarR: 4.75\n",
      "Train Epoch: 1 [0/2500 (0%)]\n",
      "Tr Loss: 1.368103 | MeanR: -12.65 | VarR: 4.80\n",
      "Train Epoch: 1 [640/2500 (36%)]\n",
      "Tr Loss: 1.343412 | MeanR: -10.89 | VarR: 4.23\n",
      "Train Epoch: 1 [1280/2500 (71%)]\n",
      "Tr Loss: 1.094646 | MeanR: -11.31 | VarR: 4.81\n",
      "Train Epoch: 2 [0/2500 (0%)]\n",
      "Tr Loss: 1.281374 | MeanR: -12.36 | VarR: 4.40\n",
      "Train Epoch: 2 [640/2500 (36%)]\n",
      "Tr Loss: 1.110748 | MeanR: -12.38 | VarR: 5.54\n",
      "Train Epoch: 2 [1280/2500 (71%)]\n",
      "Tr Loss: 1.193671 | MeanR: -12.12 | VarR: 4.07\n",
      "Train Epoch: 3 [0/2500 (0%)]\n",
      "Tr Loss: 0.978873 | MeanR: -12.45 | VarR: 4.29\n",
      "Train Epoch: 3 [640/2500 (36%)]\n",
      "Tr Loss: 1.126318 | MeanR: -12.71 | VarR: 3.92\n",
      "Train Epoch: 3 [1280/2500 (71%)]\n",
      "Tr Loss: 1.041594 | MeanR: -10.96 | VarR: 5.04\n"
     ]
    }
   ],
   "source": [
    "modelD = ReacherDisModel(dropout)\n",
    "modelD.cuda()\n",
    "opt = optim.Adam(modelD.parameters())\n",
    "\n",
    "mle_evals = train(modelD, opt, entro.cross_entro_loss, train_loader, test_loader, n_classes, epochs, predictD_gen(d), \n",
    "      n_samples=n_samples, log_interval=log_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('results/reacher_mle_evals.pkl', 'w') as f:\n",
    "    dump(mle_evals, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# define model\n",
    "class ReacherModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ReacherModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(11, 100)\n",
    "        self.fc2 = nn.Linear(100, 50)\n",
    "        self.fc3 = nn.Linear(50, 10)\n",
    "        self.fc4 = nn.Linear(10, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = ReacherModel()\n",
    "model.cuda()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "train(model, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model.state_dict(), './models/reacher_cont.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ReacherModel (\n",
       "  (fc1): Linear (11 -> 100)\n",
       "  (fc2): Linear (100 -> 50)\n",
       "  (fc3): Linear (50 -> 10)\n",
       "  (fc4): Linear (10 -> 2)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model\n",
    "model2 = ReacherModel()\n",
    "model2.load_state_dict(torch.load('./models/reacher_cont.pt'))\n",
    "model2.cuda()\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0\n",
      "(1, 40)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 40 into shape (1,1,30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-144-13e5432dd9c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meval_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictD_gen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-131-4a687d12a6e7>\u001b[0m in \u001b[0;36meval_model\u001b[1;34m(model, f, n)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mtotalr\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-143-f072d6c3642f>\u001b[0m in \u001b[0;36mpredictD\u001b[1;34m(model, X)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mn_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bins\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mYd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mYd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_action\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_action\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 40 into shape (1,1,30)"
     ]
    }
   ],
   "source": [
    "eval_model(modelD, predictD_gen(d), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.0726575280658706"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reacher_data['mean_return']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
